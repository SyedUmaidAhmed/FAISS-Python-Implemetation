{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "420dPmKH8sTi"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import logging\n",
    "import uuid\n",
    "import sys\n",
    "import heapq\n",
    "import numpy as np\n",
    "import sys, faiss\n",
    "\n",
    "\n",
    "\n",
    "def GET_FAISS_RESOURCES():\n",
    "    return None\n",
    "\n",
    "def GET_FAISS_INDEX(index_path):\n",
    "    import faiss\n",
    "    index = faiss.read_index(index_path)\n",
    "    return index\n",
    "\n",
    "def GET_FAISS_ID_TO_VECTOR(ids_vectors_path):\n",
    "    if not os.path.exists(ids_vectors_path):\n",
    "      return None\n",
    "    with open(ids_vectors_path, 'rb') as f:\n",
    "      index_dict = pickle.load(f)\n",
    "    def id_to_vector(id_):\n",
    "      try:\n",
    "        return index_dict[id_]\n",
    "      except:\n",
    "        pass\n",
    "    return id_to_vector\n",
    "\n",
    "\n",
    "NOR_X = 512\n",
    "NOR_Y = 384\n",
    "\n",
    "PHASH_X = 8\n",
    "PHASH_Y = 8\n",
    "\n",
    "SIFT_DIMENSIONS = 128\n",
    "\n",
    "NUM_FEATURES = 100\n",
    "isAddPhash = False\n",
    "\n",
    "bow_num_words = 1000\n",
    "dictionary_path = '/faiss-web-service/resources/dictionary'\n",
    "\n",
    "INDEX_KEY = \"IDMap,PCA128,IVF2048,PQ16\"\n",
    "\n",
    "TOP_N = 5\n",
    "SIMILARITY = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "ArUAI_ATYdQu"
   },
   "outputs": [],
   "source": [
    "def calc_phash(gray_image):\n",
    "  img = gray_image\n",
    "\n",
    "\n",
    "  img = cv2.resize(img, (PHASH_X, PHASH_Y), interpolation=cv2.INTER_CUBIC)\n",
    "  h, w = img.shape[:2]\n",
    "  vis0 = np.zeros((h, w), np.float32)\n",
    "  vis0[:h, :w] = img\n",
    "  vis1 = cv2.dct(cv2.dct(vis0))\n",
    "  vis1.resize(PHASH_X, PHASH_Y)\n",
    "  img_list = vis1.flatten()\n",
    "  avg = sum(img_list) * 1. / len(img_list)\n",
    "  avg_list = [np.float32(0) if i < avg else np.float32(1) for i in img_list]\n",
    "  return np.matrix(avg_list).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "oP1NJDxQYy3P"
   },
   "outputs": [],
   "source": [
    "def adddPhash(gray_image, des):\n",
    "  phash = calc_phash(gray_image)\n",
    "  n, d = des.shape\n",
    "  phash_mat = phash\n",
    "  for i in range(n - 1):\n",
    "    phash_mat = np.vstack((phash_mat, phash))\n",
    "  des = np.hstack((des, phash_mat))\n",
    "  return des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "gDhgxc0RZLYz"
   },
   "outputs": [],
   "source": [
    "def calc_sift(sift, image_file):\n",
    "  if not os.path.isfile(image_file):\n",
    "    logging.error('Image:{} does not exist'.format(image_file))\n",
    "    return -1, None\n",
    "  try:\n",
    "    image_o = cv2.imread(image_file)\n",
    "  except:\n",
    "    logging.error('Open Image:{} failed'.format(image_file))\n",
    "    return -1, None\n",
    "  if image_o is None:\n",
    "    logging.error('Open Image:{} failed'.format(image_file))\n",
    "    return -1, None\n",
    "  image = cv2.resize(image_o, (NOR_X, NOR_Y))\n",
    "  if image.ndim == 2:\n",
    "    gray_image = image\n",
    "  else:\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray_image, (5, 5), 0)\n",
    "    equalized = cv2.equalizeHist(blurred)\n",
    "      \n",
    "  kp, des = sift.detectAndCompute(equalized, None)\n",
    "  if isAddPhash:\n",
    "    des = adddPhash(gray_image, des)\n",
    "  sift_feature = np.matrix(des)\n",
    "  return 0, sift_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "-hOlYmj-Z4My"
   },
   "outputs": [],
   "source": [
    "def get_sift():\n",
    "  return cv2.SIFT_create()\n",
    "\n",
    "#nfeatures=NUM_FEATURES, nOctaveLayers=3, contrastThreshold=0.04, edgeThreshold=10, sigma=1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "W2wk_ulWaFpG"
   },
   "outputs": [],
   "source": [
    "def get_vectors(sift, image):\n",
    "  return calc_sift(sift, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "UtZfg2iSyT9T"
   },
   "outputs": [],
   "source": [
    "def iterate_files(_dir):\n",
    "  result = []\n",
    "  for root, dirs, files in os.walk(_dir, topdown=True):\n",
    "    for fl in files:\n",
    "      if fl.endswith(\"jpg\") or fl.endswith(\".JPG\"):\n",
    "        result.append(os.path.join(root, fl))\n",
    "  '''for files in os.walk(_dir, topdown=True):\n",
    "    (x, y, z) = files\n",
    "  for fl in z:\n",
    "    if fl.endswith(\"jpg\") or fl.endswith(\"JPG\"):\n",
    "      result.append(os.path.join(x, fl))'''\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "_hhXDclxfbSG"
   },
   "outputs": [],
   "source": [
    "img_list = iterate_files(r\"D:\\API_APP\\FAST_FAISS_HNSW\\processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "ka3hgn94f2YG"
   },
   "outputs": [],
   "source": [
    "files = os.walk(r\"D:\\API_APP\\FAST_FAISS_HNSW\\processed\", topdown=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "i_0lh6xugH9v"
   },
   "outputs": [],
   "source": [
    "for f in files:\n",
    "  (x, y, z) = f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5kNGrZK1qG8a",
    "outputId": "4a89327b-748b-4924-90b9-b53071e4ca4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929\n"
     ]
    }
   ],
   "source": [
    "print(len(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "9bjdcUkyp8VQ"
   },
   "outputs": [],
   "source": [
    "res1 = []\n",
    "for fl in z:\n",
    "  if fl.endswith(\"jpg\") or fl.endswith(\"JPG\"):\n",
    "    res1.append(os.path.join(x, fl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Pt5j-VPgLb4",
    "outputId": "5af0fe30-e92d-48d7-9445-8e662ef96dd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929\n"
     ]
    }
   ],
   "source": [
    "print(len(res1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "id": "a7gk31VFmYBa"
   },
   "outputs": [],
   "source": [
    "dimensions = SIFT_DIMENSIONS\n",
    "if isAddPhash:\n",
    "  dimensions += PHASH_X * PHASH_Y\n",
    "index = faiss.index_factory(dimensions, INDEX_KEY)\n",
    "\n",
    "images_list = iterate_files(r\"D:\\API_APP\\FAST_FAISS_HNSW\\processed\")\n",
    "ids_count = 0\n",
    "index_dict = {}\n",
    "ids = None\n",
    "features = np.matrix([])\n",
    "sift = get_sift()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WHQFs_S-m6Tj",
    "outputId": "01f0fb9a-da69-47f0-8c73-b4e9047b3e39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "done adding\n"
     ]
    }
   ],
   "source": [
    "for file_name in images_list:\n",
    "  ret, sift_feature = calc_sift(sift, file_name)\n",
    "  if ret == 0 and sift_feature.any():\n",
    "    image_dict = {ids_count: (file_name, sift_feature)}\n",
    "    index_dict.update(image_dict)\n",
    "    #print(sift_feature.shape[0])\n",
    "    ids_list = np.linspace(ids_count, ids_count, num=sift_feature.shape[0], dtype=\"int64\")\n",
    "    ids_count += 1\n",
    "    if features.any():\n",
    "      features = np.vstack((features, sift_feature))\n",
    "      ids = np.hstack((ids, ids_list))\n",
    "    else:\n",
    "      features = sift_feature\n",
    "      ids = ids_list\n",
    "    if ids_count % 9000000 == 8999999:\n",
    "      if not index.is_trained and INDEX_KEY != \"IDMap,Flat\":\n",
    "        index.train(features)\n",
    "      index.add_with_ids(features, ids)\n",
    "      ids = None\n",
    "      features = np.matrix([])\n",
    "if features.any():\n",
    "  if not index.is_trained and INDEX_KEY != \"IDMap,Flat\":\n",
    "    index.train(features)\n",
    "    print('done training')\n",
    "  index.add_with_ids(features, ids)\n",
    "  print('done adding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0hXocLDhl-pV",
    "outputId": "dc8b1f0b-0773-452f-9a57-fcec08622dce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('D:\\\\API_APP\\\\FAST_FAISS_HNSW\\\\processed\\\\IMG_0068.JPG',\n",
       " matrix([[  0.,   0.,   0., ...,   0.,   0.,   1.],\n",
       "         [  8.,  21., 118., ...,   0.,   0.,   0.],\n",
       "         [  1.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         ...,\n",
       "         [  0.,   1.,  20., ...,   0.,   0.,   0.],\n",
       "         [  0.,  15., 128., ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., ...,  16.,   5.,   2.]], dtype=float32))"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_dict[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "id": "neWnxcM9ceSb"
   },
   "outputs": [],
   "source": [
    "ids_vectors_path = 'ids_path_vectors'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w29j37avdWrP",
    "outputId": "95f77270-232b-4279-c60d-219e93b32c3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "3844010\n"
     ]
    }
   ],
   "source": [
    "print(index.is_trained)\n",
    "print(index.ntotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "id": "8ASX-ouCn6nE"
   },
   "outputs": [],
   "source": [
    "with open(ids_vectors_path, 'wb+') as f:\n",
    "  try:\n",
    "    pickle.dump(index_dict, f, True)\n",
    "  except EnvironmentError as e:\n",
    "    logging.error('Failed to save index file error:[{}]'.format(e))\n",
    "    f.close()\n",
    "  except RuntimeError:\n",
    "    logging.error('Failed to save index file error:[{}]'.format(v))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "M_J7URVS_zSW",
    "outputId": "4fd8accb-946a-4a35-d770-55951dafb0ea"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "id": "iA5lH7cryCSM"
   },
   "outputs": [],
   "source": [
    "id_to_vector = GET_FAISS_ID_TO_VECTOR('ids_path_vectors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZiSIdEjOoXKd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "id": "yhGbusCGop5U"
   },
   "outputs": [],
   "source": [
    "class FaissIndex(object):\n",
    "  def __init__(self, index, id_to_vector):\n",
    "    assert index\n",
    "    self.index = index\n",
    "    self.id_to_vector = id_to_vector\n",
    "    self.sift = get_sift()\n",
    "  \n",
    "  def search_by_ids(self, ids, k):\n",
    "    vectors = [self.id_to_vector(id_)[1] for id_ in ids]\n",
    "    results = self.__search__(ids, vectors, k + 1)\n",
    "    return results\n",
    "\n",
    "  def search_by_vectors(self, vectors, k):\n",
    "    vectors = read_array(vectors, SIFT_DIMENSIONS)\n",
    "    count = vectors.shape[0]\n",
    "    vectors = np.vstack((vectors, vectors))\n",
    "    vectors = vectors[0:count, :]\n",
    "    print(vectors.shape)\n",
    "    ids = [None]\n",
    "    results = self.__search__(ids, [vectors], k)\n",
    "    return results\n",
    "\n",
    "  def search_by_image(self, image, k):\n",
    "    ids = [None]\n",
    "    ret, vectors = get_vectors(self.sift, image)\n",
    "    print(ret)\n",
    "    results = self.__search__(ids, [vectors], k)\n",
    "    return results\n",
    "\n",
    "  def __search__(self, ids, vectors, topN):\n",
    "    def neighbor_dict_with_path(id_, file_path, score):\n",
    "      return {'id': float(id_), 'file_path': file_path, 'score': score}\n",
    "    def neighbor_dict(id_, score):\n",
    "      return {'id': float(id_), 'score': score}\n",
    "    def result_dict_str(id_, neighbors):\n",
    "      return {'id': id_, 'neighbors': neighbors}\n",
    "    results = []\n",
    "    need_hit = SIMILARITY\n",
    "    for id_, siftfeature in zip(ids, vectors):\n",
    "      scores, neighbors = self.index.search(siftfeature, k=topN) if siftfeature.size > 0 else ([], [])\n",
    "      print(neighbors)\n",
    "      n, d = neighbors.shape\n",
    "      result_dict = {}\n",
    "      for i in range(n):\n",
    "        l = np.unique(neighbors[i]).tolist()\n",
    "        for r_id in l:\n",
    "          if r_id != -1:\n",
    "            score = result_dict.get(r_id, 0)\n",
    "            score += 1\n",
    "            result_dict[r_id] = score\n",
    "      h = []\n",
    "      for k in result_dict:\n",
    "        v = result_dict[k]\n",
    "        if v >= need_hit:\n",
    "          if len(h) < topN:\n",
    "            heapq.heappush(h, (v, k))\n",
    "          else:\n",
    "            heapq.heappushpop(h, (v, k))\n",
    "      result_list = heapq.nlargest(topN, h, key=lambda x: x[0])\n",
    "      neighbors_scores = []\n",
    "      for e in result_list:\n",
    "        confidence = e[0] * 100 / n\n",
    "        if self.id_to_vector:\n",
    "          print(\"A\")\n",
    "          file_path = self.id_to_vector(e[1])[0]\n",
    "          neighbors_scores.append(neighbor_dict_with_path(e[1], file_path, str(confidence)))\n",
    "        else:\n",
    "          neighbors_scores.append(neighbor_dict(e[1], str(confidence)))\n",
    "      results.append(result_dict_str(id_, neighbors_scores))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "id": "67YHVGIpf-eq"
   },
   "outputs": [],
   "source": [
    "fs2 = FaissIndex(index=index, id_to_vector=id_to_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gthcwhAzgsz2",
    "outputId": "cad11134-169b-413b-8d5d-180a50f639c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[[1616  701  598]\n",
      " [1828   16 1574]\n",
      " [ 525  791  319]\n",
      " ...\n",
      " [ 513  120   39]\n",
      " [ 424 1496 1897]\n",
      " [1218  829  830]]\n",
      "A\n",
      "A\n",
      "A\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': None,\n",
       "  'neighbors': [{'id': 665.0,\n",
       "    'file_path': 'D:\\\\API_APP\\\\FAST_FAISS_HNSW\\\\processed\\\\IMG_0850.JPG',\n",
       "    'score': '0.6251860672819292'},\n",
       "   {'id': 319.0,\n",
       "    'file_path': 'D:\\\\API_APP\\\\FAST_FAISS_HNSW\\\\processed\\\\IMG_0407.JPG',\n",
       "    'score': '0.5656445370646026'},\n",
       "   {'id': 315.0,\n",
       "    'file_path': 'D:\\\\API_APP\\\\FAST_FAISS_HNSW\\\\processed\\\\IMG_0403.JPG',\n",
       "    'score': '0.5358737719559392'}]}]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs2.search_by_image(\"./Not_DB/7.jpg\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zUYBUSK_ljGy"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "loftr",
   "language": "python",
   "name": "loftr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
